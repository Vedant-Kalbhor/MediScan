{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, data_dir, classes, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "\n",
    "        # collect image paths and labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for label, class_name in enumerate(classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for file in os.listdir(class_dir):\n",
    "                if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(class_dir, file))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[\"glioma\",\"meningioma\",\"pituitary\",\"notumor\"]\n",
    "\n",
    "data_dir=\"./brain_dataset\"\n",
    "train_dir=os.path.join(data_dir,\"Training\")\n",
    "test_dir=os.path.join(data_dir,\"Testing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225]),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "train_ds = BrainTumorDataset(train_dir, classes, transform=train_transform)\n",
    "test_ds = BrainTumorDataset(test_dir, classes, transform=val_transform)\n",
    "\n",
    "num_workers = os.cpu_count() \n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\.conda\\envs\\dl-gpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vedan\\.conda\\envs\\dl-gpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model=models.resnet18(pretrained=True)\n",
    "num_ftrs=model.fc.in_features\n",
    "model.fc=nn.Linear(num_ftrs,len(classes))\n",
    "model=model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-4)\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer,\"min\",patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss=float(\"inf\")\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss=0.2728 Acc=0.8980 | Val Loss=0.0960 Acc=0.9641\n",
      "✅ Saved best model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss=0.1027 Acc=0.9665 | Val Loss=0.0707 Acc=0.9834\n",
      "✅ Saved best model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss=0.0619 Acc=0.9799 | Val Loss=0.0551 Acc=0.9834\n",
      "✅ Saved best model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss=0.0466 Acc=0.9851 | Val Loss=0.0602 Acc=0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss=0.0412 Acc=0.9858 | Val Loss=0.0620 Acc=0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss=0.0197 Acc=0.9945 | Val Loss=0.0472 Acc=0.9869\n",
      "✅ Saved best model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss=0.0227 Acc=0.9926 | Val Loss=0.0541 Acc=0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss=0.0186 Acc=0.9954 | Val Loss=0.0534 Acc=0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss=0.0218 Acc=0.9939 | Val Loss=0.0572 Acc=0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss=0.0079 Acc=0.9989 | Val Loss=0.0344 Acc=0.9930\n",
      "✅ Saved best model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # safer in Jupyter/Colab\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# ===================================================\n",
    "# Auto-split Training dataset into Train + Validation\n",
    "# ===================================================\n",
    "\n",
    "# Assuming `train_ds` is created from Training/ directory earlier\n",
    "val_size = int(0.2 * len(train_ds))  # 20% for validation\n",
    "train_size = len(train_ds) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "# DataLoaders (Windows-safe num_workers)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# ===================================================\n",
    "# Safety Flags for Stable GPU Training\n",
    "# ===================================================\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# ===================================================\n",
    "# Training Loop\n",
    "# ===================================================\n",
    "best_val_loss = float(\"inf\")\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", leave=False)\n",
    "\n",
    "    for inputs, labels in train_pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"acc\": f\"{(running_corrects.double() / ((len(train_pbar)*train_loader.batch_size))).item():.3f}\"\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / len(train_ds)\n",
    "    epoch_acc = running_corrects.double() / len(train_ds)\n",
    "\n",
    "    # ===================================================\n",
    "    # Validation Step\n",
    "    # ===================================================\n",
    "    model.eval()\n",
    "    val_loss, val_corrects = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Validating\", unit=\"batch\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    val_loss = val_loss / len(val_ds)\n",
    "    val_acc = val_corrects.double() / len(val_ds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss={epoch_loss:.4f} Acc={epoch_acc:.4f} | \"\n",
    "          f\"Val Loss={val_loss:.4f} Acc={val_acc:.4f}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # ===================================================\n",
    "    # Save Best Model\n",
    "    # ===================================================\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_brain_tumor_resnet18.pth\")\n",
    "        print(\"✅ Saved best model.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_26556\\2316853588.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_brain_tumor_resnet18.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_brain_tumor_resnet18.pth\"))\n",
    "model.eval()\n",
    "test_corrects=0\n",
    "total=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(inputs)\n",
    "        _,preds=torch.max(outputs,1)\n",
    "        test_corrects+=torch.sum(preds==labels.data)\n",
    "        total+=labels.size(0)\n",
    "\n",
    "test_acc=test_corrects.double()/total\n",
    "print(\"Test accuracy:\", test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully:\n",
      "   → Training samples: 4570\n",
      "   → Validation samples: 1142\n",
      "   → Testing samples: 1311\n",
      "💻 Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\.conda\\envs\\dl-gpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vedan\\.conda\\envs\\dl-gpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# # brain_tumor_train.ipynb\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset, random_split\n",
    "# from torchvision import transforms, models\n",
    "\n",
    "# # ==========================================\n",
    "# # Custom Dataset Class\n",
    "# # ==========================================\n",
    "\n",
    "# class BrainTumorDataset(Dataset):\n",
    "#     def __init__(self, root_dir, classes, transform=None):\n",
    "#         \"\"\"\n",
    "#         Custom Dataset for Brain Tumor MRI images.\n",
    "#         Args:\n",
    "#             root_dir (str): path to folder containing class subfolders.\n",
    "#             classes (list): list of class names.\n",
    "#             transform (torchvision.transforms): preprocessing transforms.\n",
    "#         \"\"\"\n",
    "#         self.root_dir = root_dir\n",
    "#         self.classes = classes\n",
    "#         self.transform = transform\n",
    "#         self.image_paths = []\n",
    "#         self.labels = []\n",
    "\n",
    "#         for idx, cls in enumerate(classes):\n",
    "#             cls_folder = os.path.join(root_dir, cls)\n",
    "#             if not os.path.isdir(cls_folder):\n",
    "#                 continue\n",
    "#             for fname in os.listdir(cls_folder):\n",
    "#                 if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "#                     self.image_paths.append(os.path.join(cls_folder, fname))\n",
    "#                     self.labels.append(idx)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.image_paths[idx]\n",
    "#         label = self.labels[idx]\n",
    "#         image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image, label\n",
    "\n",
    "\n",
    "# # ==========================================\n",
    "# # Paths & Config\n",
    "# # ==========================================\n",
    "\n",
    "# # Your dataset structure\n",
    "# # brain_dataset/\n",
    "# # ├── Training/\n",
    "# # └── Testing/\n",
    "\n",
    "# classes = [\"glioma\", \"meningioma\", \"pituitary\", \"notumor\"]\n",
    "\n",
    "# data_dir = r\"C:\\Users\\vedan\\MediScan\\brain_dataset\"\n",
    "# train_dir = os.path.join(data_dir, \"Training\")\n",
    "# test_dir = os.path.join(data_dir, \"Testing\")\n",
    "\n",
    "# # ==========================================\n",
    "# # Data Transforms\n",
    "# # ==========================================\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(15),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# # ==========================================\n",
    "# # Dataset & Auto-Split for Validation\n",
    "# # ==========================================\n",
    "\n",
    "# # Load entire training dataset first\n",
    "# full_train_ds = BrainTumorDataset(train_dir, classes, transform=train_transform)\n",
    "\n",
    "# # Split into train (80%) and validation (20%)\n",
    "# val_size = int(0.2 * len(full_train_ds))\n",
    "# train_size = len(full_train_ds) - val_size\n",
    "# train_ds, val_ds = random_split(full_train_ds, [train_size, val_size])\n",
    "\n",
    "# # Load test dataset separately\n",
    "# test_ds = BrainTumorDataset(test_dir, classes, transform=val_transform)\n",
    "\n",
    "# print(f\"✅ Dataset loaded successfully:\")\n",
    "# print(f\"   → Training samples: {len(train_ds)}\")\n",
    "# print(f\"   → Validation samples: {len(val_ds)}\")\n",
    "# print(f\"   → Testing samples: {len(test_ds)}\")\n",
    "\n",
    "# # ==========================================\n",
    "# # DataLoader Setup\n",
    "# # ==========================================\n",
    "\n",
    "# num_workers = max(0, (os.cpu_count() // 2) if torch.cuda.is_available() else 0)\n",
    "\n",
    "# train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "# val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "# test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"💻 Using device:\", device)\n",
    "\n",
    "# # ==========================================\n",
    "# # Model Setup (Transfer Learning)\n",
    "# # ==========================================\n",
    "\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, len(classes))\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=3)\n",
    "\n",
    "# # ==========================================\n",
    "# # Training Loop\n",
    "# # ==========================================\n",
    "\n",
    "# num_epochs = 10\n",
    "# best_val_loss = float(\"inf\")\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     running_corrects = 0\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#     epoch_loss = running_loss / len(train_ds)\n",
    "#     epoch_acc = running_corrects.double() / len(train_ds)\n",
    "\n",
    "#     # ===== Validation =====\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     val_corrects = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item() * inputs.size(0)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#     val_loss = val_loss / len(val_ds)\n",
    "#     val_acc = val_corrects.double() / len(val_ds)\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "#           f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f} \"\n",
    "#           f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "#     scheduler.step(val_loss)\n",
    "\n",
    "#     # Save best model\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         torch.save(model.state_dict(), \"best_brain_tumor_resnet18.pth\")\n",
    "#         print(\"💾 Saved best model.\\n\")\n",
    "\n",
    "# # ==========================================\n",
    "# # Testing\n",
    "# # ==========================================\n",
    "\n",
    "# model.load_state_dict(torch.load(\"best_brain_tumor_resnet18.pth\", map_location=device))\n",
    "# model.eval()\n",
    "\n",
    "# test_corrects = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in test_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         test_corrects += torch.sum(preds == labels.data)\n",
    "#         total += labels.size(0)\n",
    "\n",
    "# test_acc = test_corrects.double() / total\n",
    "# print(f\"✅ Test Accuracy: {test_acc.item():.4f}\")\n",
    "\n",
    "# # ==========================================\n",
    "# # Visualization (Optional)\n",
    "# # ==========================================\n",
    "\n",
    "# def visualize_predictions(model, ds, num=6):\n",
    "#     model.eval()\n",
    "#     fig = plt.figure(figsize=(12, 6))\n",
    "#     for i in range(num):\n",
    "#         img, label = ds[i]\n",
    "#         input_img = img.unsqueeze(0).to(device)\n",
    "#         with torch.no_grad():\n",
    "#             output = model(input_img)\n",
    "#             _, pred = torch.max(output, 1)\n",
    "#         ax = fig.add_subplot(1, num, i+1)\n",
    "#         npimg = img.permute(1, 2, 0).cpu().numpy()\n",
    "#         npimg = (npimg * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "#         npimg = np.clip(npimg, 0, 1)\n",
    "#         ax.imshow(npimg)\n",
    "#         ax.set_title(f\"GT: {classes[label]}\\nPred: {classes[pred.item()]}\")\n",
    "#         ax.axis(\"off\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# visualize_predictions(model, test_ds, num=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
